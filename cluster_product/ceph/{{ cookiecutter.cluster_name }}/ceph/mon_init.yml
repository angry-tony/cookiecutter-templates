classes:
- system.ceph.mon.cluster_init
parameters:
{%- if cookiecutter.ceph_osd_count|int < 5 %}
{% set num = 128 %}
{%- elif cookiecutter.ceph_osd_count|int >= 5 and cookiecutter.ceph_osd_count|int <= 10 %}
{% set num = 512 %}
{%- else %}
{% set num = 1024 %}
{%- endif %}
  ceph:
    setup:
      pool:
        images:
          pg_num: {{ num }}
          pgp_num: {{ num }}
          type: replicated
        volumes:
          pg_num: {{ num }}
          pgp_num: {{ num }}
          type: replicated
        vms:
          pg_num: {{ num }}
          pgp_num: {{ num }}
          type: replicated

# customize to setup crush map
#       pool:
#         rbd:
#           pg_num: 2084
#           pgp_num: 2048
#           type: replicated
#           min_size: 2
#           size: 3
#         replicated_pool:
#           pg_num: 512
#           pgp_num: 512
#           type: replicated
#         erasure_pool:
#           pg_num: 256
#           pgp_num: 256
#           type: erasure
#       crush:
#         tunables:
#           choose_total_tries: 50
#         type:
#           - root
#           - region
#           - rack
#           - host
#         root:
#           - name: root1
#           - name: root2
#         region:
#           - name: eu-1
#             parent: root1
#           - name: eu-2
#             parent: root1
#           - name: us-1
#             parent: root2
#         rack:
#           - name: rack01
#             parent: eu-1
#           - name: rack02
#             parent: eu-2
#           - name: rack03
#             parent: us-1
#         rule:
#           sata:
#             ruleset: 0
#             type: replicated
#             min_size: 1
#             max_size: 10
#             steps:
#               - take crushroot.performanceblock.satahss.1
#               - chooseleaf firstn 0 type failure_domain
#               - emit